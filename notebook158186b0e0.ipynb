{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os \n\nimport matplotlib.pyplot as plt\nfrom PIL import Image \nfrom glob import glob\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#Importing keras libraries and packages\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import MaxPooling2D","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:00:09.735607Z","iopub.execute_input":"2021-06-30T14:00:09.736223Z","iopub.status.idle":"2021-06-30T14:00:09.745423Z","shell.execute_reply.started":"2021-06-30T14:00:09.736179Z","shell.execute_reply":"2021-06-30T14:00:09.744218Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/fruits/fruits-360/Training/'\ntest_path = '../input/fruits/fruits-360/Test/'","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:00:12.013364Z","iopub.execute_input":"2021-06-30T14:00:12.013739Z","iopub.status.idle":"2021-06-30T14:00:12.018422Z","shell.execute_reply.started":"2021-06-30T14:00:12.013709Z","shell.execute_reply":"2021-06-30T14:00:12.017029Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Model configuration\nbatch_size = 25\nimg_width, img_height, img_num_channels = 100, 100, 3\nloss_function = sparse_categorical_crossentropy\nno_epochs = 25\noptimizer = Adam()\nvalidation_split = 0.2\nverbosity = 1\n\n# Determine shape of the data\ninput_shape = (img_width, img_height, img_num_channels)\n\n# Create a generator\ndatagen = ImageDataGenerator(\n  rescale=1./255\n)\ntrain_datagen = datagen.flow_from_directory(\n        train_path,\n#         save_to_dir='./',\n#         save_format='jpeg',\n        batch_size=100,\n        target_size=(100, 100),\n        class_mode='sparse')\ntest_datagen = datagen.flow_from_directory(\n\n        test_path,\n#         save_to_dir='./',\n#         save_format='jpeg',\n        batch_size=100,\n        target_size=(100, 100),\n        class_mode='sparse')","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:00:41.352889Z","iopub.execute_input":"2021-06-30T14:00:41.353259Z","iopub.status.idle":"2021-06-30T14:00:46.632544Z","shell.execute_reply.started":"2021-06-30T14:00:41.353230Z","shell.execute_reply":"2021-06-30T14:00:46.631175Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 67692 images belonging to 131 classes.\nFound 22688 images belonging to 131 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create the model\nmodel = Sequential()\nmodel.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Dropout(.2))\n\nmodel.add(Conv2D(32, kernel_size=(5, 5), activation='relu'))\nmodel.add(Flatten())\n\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(131, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:01:40.916477Z","iopub.execute_input":"2021-06-30T14:01:40.917135Z","iopub.status.idle":"2021-06-30T14:01:41.070989Z","shell.execute_reply.started":"2021-06-30T14:01:40.917070Z","shell.execute_reply":"2021-06-30T14:01:41.069541Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Display a model summary\nmodel.summary()\n\n# Compile the model\nmodel.compile(loss=loss_function,\n              optimizer=optimizer,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:02:05.272249Z","iopub.execute_input":"2021-06-30T14:02:05.272643Z","iopub.status.idle":"2021-06-30T14:02:05.303603Z","shell.execute_reply.started":"2021-06-30T14:02:05.272597Z","shell.execute_reply":"2021-06-30T14:02:05.302272Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 96, 96, 16)        1216      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 48, 48, 16)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 48, 48, 16)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 44, 44, 32)        12832     \n_________________________________________________________________\nflatten (Flatten)            (None, 61952)             0         \n_________________________________________________________________\ndense (Dense)                (None, 16)                991248    \n_________________________________________________________________\ndense_1 (Dense)              (None, 131)               2227      \n=================================================================\nTotal params: 1,007,523\nTrainable params: 1,007,523\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('weights.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n# Start training\nmodel.fit(\n        train_datagen,\n        steps_per_epoch=60000//200,\n        validation_data=test_datagen,\n        validation_steps=20000//100,\n        callbacks=[checkpoint],\n        epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:02:28.810341Z","iopub.execute_input":"2021-06-30T14:02:28.811024Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n300/300 [==============================] - 373s 1s/step - loss: 4.4759 - accuracy: 0.0386 - val_loss: 3.3328 - val_accuracy: 0.1580\n\nEpoch 00001: val_accuracy improved from -inf to 0.15800, saving model to weights.hdf5\nEpoch 2/10\n280/300 [===========================>..] - ETA: 13s - loss: 2.9272 - accuracy: 0.1978","output_type":"stream"}]},{"cell_type":"code","source":"model2=Sequential()\nmodel2.add(Conv2D(32, (3,3), input_shape=input_shape,activation='swish'))\nmodel2.add(MaxPooling2D())\nmodel2.add(Dropout(.1))\n\nmodel2.add(Conv2D(64, (3,3),activation='swish'))\nmodel2.add(MaxPooling2D())\nmodel2.add(Dropout(.1))\n\nmodel2.add(Conv2D(128, (3,3),activation='swish'))\nmodel2.add(MaxPooling2D())\nmodel2.add(Dropout(.1))\n\nmodel2.add(Conv2D(256,(3,3),activation='swish'))\nmodel2.add(MaxPooling2D())\nmodel2.add(Dropout(.1))\n\n\nmodel2.add(Flatten())\nmodel2.add(Dense(512,activation='swish'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(131,activation='softmax'))\n# Display a model summary\nmodel2.summary()\n\n# Compile the model\nmodel2.compile(loss=loss_function,\n              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              metrics=['accuracy'])\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('weight2s.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\nmodel2.fit(\n        train_datagen,\n        steps_per_epoch=60000//200,\n        validation_data=test_datagen,\n        validation_steps=20000//100,\n        callbacks=[checkpoint],\n        epochs=10)","metadata":{},"execution_count":null,"outputs":[]}]}